{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research on CLS",
      "provenance": [],
      "collapsed_sections": [
        "oYRlVAO-9UtW",
        "OjlXGsP2atqC",
        "TLmL94KcLwpa",
        "pMazIGvCQU4Y",
        "0Zs7GKQkQWsu",
        "shvGGAQgQxwu",
        "lg-c0IO7Vp8H",
        "Y4AM3W1jLc2I",
        "b4wYvQkiluMh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Student Numbers:\n",
        "\n",
        "18071472\n",
        "\n",
        "18017060\n",
        "\n",
        "21104272\n",
        "\n",
        "21047887"
      ],
      "metadata": {
        "id": "WQ9ZfA7PEkxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Related Packages/Files\n",
        "\n",
        "Lecturers and TAs, you should run this to get the essential packages and trained models for testing.\n",
        "\n",
        "      1. Upgrade gdown (For downloading 3 and 4)\n",
        "      2. Download HuggingFace's Transformers package\n",
        "      3. Download the Pre-processed Data\n",
        "      4. Download the Trained Models"
      ],
      "metadata": {
        "id": "oYRlVAO-9UtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade gdown\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# Download HuggingFace's package\n",
        "!pip install transformers\n",
        "\n",
        "# Download Data\n",
        "!gdown 1nWNc8QmJBb3oMvUUjTkLbxM7RnaqL4da\n",
        "\n",
        "# If the above one doesn't work, try this one\n",
        "# !gdown 1hD2hO8qMaHFzjK2_vZb7eF61oSW7hV_9\n",
        "\n",
        "!unzip data.zip\n",
        "\n",
        "# Download trained models\n",
        "!gdown 1mSRIFcseKq3Xje3CFGWFVyD82Vzr8D-m\n",
        "\n",
        "# If the above one doesn't work, try this one\n",
        "# !gdown 1uMRUVn_Aif-FMpLOa1TxfjRubHi3Us0M\n",
        "\n",
        "!unzip models.zip"
      ],
      "metadata": {
        "id": "adzJ82cRpnOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "For Lecturers and TAs, you don't have to run this part."
      ],
      "metadata": {
        "id": "OjlXGsP2atqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "UVn1Oxl5WndV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import\n",
        "\n",
        "Lecturers and TAs, you should run this to import important packages."
      ],
      "metadata": {
        "id": "TLmL94KcLwpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "from transformers import BertTokenizerFast\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "w6SY81RUMMO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader\n",
        "\n",
        "For Lecturers and TAs, you don't have to run this part, since the testing script doesn't use the dataloader. If you want to test other parts like *model training*, *model evaluation* and *Identify Successful/Fail Cases for Each Algorithm*, you can run this.\n",
        "\n",
        "      How data is loaded can be seen in this part."
      ],
      "metadata": {
        "id": "pMazIGvCQU4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SST2_Dataset(Dataset):\n",
        "    def __init__(self, file_path, is_QA=False):\n",
        "\n",
        "        self.file = pd.read_csv(file_path, sep='\\t', header=None)\n",
        "        self.file = self.file.to_numpy()\n",
        "        self.length = self.file.shape[0]\n",
        "        self.is_QA = is_QA\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):        \n",
        "        \n",
        "        if self.is_QA:\n",
        "            x = [self.file[idx,0], self.file[idx,1]]\n",
        "            y = self.file[idx,2]\n",
        "        else:\n",
        "            x = self.file[idx,1]\n",
        "            y = self.file[idx,0]\n",
        "        \n",
        "        return x, y"
      ],
      "metadata": {
        "id": "BeJQUckPQTsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation\n",
        "\n",
        "Lecturers and TAs, you should run this to get the structure of the Models. Otherwise, the model cannot be loaded.\n",
        "\n",
        "      How the models are implemented can be seen in this part."
      ],
      "metadata": {
        "id": "0Zs7GKQkQWsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, mode, BertModel='bert-base-uncased'):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        \n",
        "        # Load Pretrained Bert Model\n",
        "        self.BertModel = AutoModel.from_pretrained(BertModel)\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.mode == 'plain' or self.mode == 'qa':\n",
        "            out = self.BertModel(**x)[1]\n",
        "            logits = self.classifier(out)\n",
        "        elif self.mode == 'all':\n",
        "            out = self.BertModel(**x)[0]\n",
        "            out = torch.relu(torch.mean(out, dim=1))\n",
        "            logits = self.classifier(out)\n",
        "        else:\n",
        "            raise Exception('Mode doesn\\'t exist!')\n",
        "        return logits\n",
        "    \n",
        "    def predict(self, x, tokeniser, device, candidate_answers = None):\n",
        "        \n",
        "        if self.mode == 'plain' or self.mode == 'all':\n",
        "            temp = tokeniser(x, return_tensors='pt').to(device)\n",
        "            return torch.argmax(self.forward(temp).reshape(-1), 0)\n",
        "        else:\n",
        "            if candidate_answers == None:\n",
        "                print('No candidate answers have been provided')\n",
        "            elif len(candidate_answers) != 2:\n",
        "                print(\"In this version, only binary candidate answers are supported\")\n",
        "            else:\n",
        "\n",
        "                temp = []\n",
        "\n",
        "                for candidate_answer in candidate_answers:\n",
        "\n",
        "                    x_args = tokenizer(x, candidate_answer,return_tensors='pt').to(device)\n",
        "                    temp.append(self.forward(x_args).reshape(-1))\n",
        "\n",
        "                return torch.argmax(torch.tensor(temp), 0)"
      ],
      "metadata": {
        "id": "cmymNLX5O5T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "\n",
        "For Lecturers and TAs, you don't have to run this part.\n",
        "\n",
        "      1. Partial fine-tuning and complete fine-tuning are in this part. \n",
        "      2. Two stage training are in this part.\n",
        "      3. The logic for training all models are in this part.\n",
        "      4. Save best models and checkpoints are in this part."
      ],
      "metadata": {
        "id": "shvGGAQgQxwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Block"
      ],
      "metadata": {
        "id": "07v2MNY1TaTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert_classifier(\n",
        "    tokenizer, \n",
        "    model, \n",
        "    model_name, \n",
        "    bert_learning_rate,\n",
        "    classifier_learning_rate,\n",
        "    train_set, \n",
        "    val_set, \n",
        "    batch_size, \n",
        "    num_epochs, \n",
        "    device, \n",
        "    criterion, \n",
        "    checkpoint_path, \n",
        "    resume_training, \n",
        "    save_epoch,\n",
        "    last_backup,\n",
        "    train_part,\n",
        "    is_QA = False\n",
        "):\n",
        "\n",
        "    trainloader = DataLoader(train_set, batch_size=batch_size,shuffle=True)\n",
        "    validloader = DataLoader(val_set, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    if train_part:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.BertModel.encoder.layer[-1].parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.BertModel.pooler.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "            \n",
        "    bert_params = model.BertModel.parameters()\n",
        "    bert_optimizer = optim.Adam(bert_params, lr=bert_learning_rate)\n",
        "    classifier_params = model.classifier.parameters()\n",
        "    classifier_optimizer = optim.Adam(classifier_params, lr=classifier_learning_rate)\n",
        "\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "    prev_epoch = 0\n",
        "    min_valid_loss = float('inf')\n",
        "\n",
        "    if resume_training:\n",
        "\n",
        "        try:\n",
        "            checkpoint = torch.load(f'{checkpoint_path}_{last_backup}.pt',map_location=device)\n",
        "        except:\n",
        "            checkpoint = torch.load(f'{checkpoint_path}_{1-last_backup}.pt',map_location=device)\n",
        "\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        bert_optimizer.load_state_dict(checkpoint['bert_optimizer_state_dict'])\n",
        "        classifier_optimizer.load_state_dict(checkpoint['classifier_optimizer_state_dict'])\n",
        "        prev_epoch = checkpoint['epoch']\n",
        "        train_loss = checkpoint['training_loss']\n",
        "        valid_loss = checkpoint['validation_loss']\n",
        "        min_valid_loss = checkpoint['min_valid_loss'] \n",
        "        del checkpoint\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    counter = 0\n",
        "    backup = 0\n",
        "    for epoch in range(prev_epoch, num_epochs):\n",
        "        \n",
        "        # Training mode\n",
        "        model.train()\n",
        "        \n",
        "        running_loss = 0\n",
        "\n",
        "        for i, train_data in enumerate(trainloader):\n",
        "\n",
        "            inputs, labels = train_data\n",
        "\n",
        "            if is_QA:\n",
        "                x_args = tokenizer([[inputs[0][j], str(inputs[1][j])] for j in range(len(labels))],return_tensors='pt',padding=True).to(device)\n",
        "                labels = labels.double().to(device)\n",
        "            else:\n",
        "                x_args = tokenizer(list(inputs),return_tensors='pt',padding=True).to(device)\n",
        "                labels = labels.to(device)\n",
        "            \n",
        "            bert_optimizer.zero_grad()\n",
        "            classifier_optimizer.zero_grad()\n",
        "\n",
        "            if is_QA:\n",
        "                outputs=model(x_args).reshape(-1)\n",
        "            else:\n",
        "                outputs=model(x_args)\n",
        "            loss=criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            bert_optimizer.step()\n",
        "            classifier_optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'epoch {epoch+1}, training loss = {running_loss/(i+1)}')\n",
        "        train_loss.append(running_loss/(i+1))\n",
        "\n",
        "        # Evaluation Mode\n",
        "        model.eval()\n",
        "        running_loss = 0\n",
        "        for i, val_data in enumerate(validloader):\n",
        "\n",
        "            inputs, labels = val_data\n",
        "            \n",
        "            if is_QA:\n",
        "                x_args = tokenizer([[inputs[0][j], str(inputs[1][j])] for j in range(len(labels))],return_tensors='pt',padding=True).to(device)\n",
        "                labels = labels.double().to(device)\n",
        "            else:\n",
        "                x_args = tokenizer(list(inputs),return_tensors='pt',padding=True).to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            if is_QA:\n",
        "                outputs=model(x_args).reshape(-1)\n",
        "            else:\n",
        "                outputs=model(x_args)\n",
        "\n",
        "            loss=criterion(outputs, labels)\n",
        "            running_loss += loss.item()  \n",
        "\n",
        "        # Save the best model\n",
        "        if running_loss/(i+1) < min_valid_loss:\n",
        "            print(f'epoch {epoch+1}, validation loss = {running_loss/(i+1)}, lowest validation loss = True, save model')  \n",
        "            torch.save(model.state_dict(), f'{model_name}.pt')    \n",
        "            min_valid_loss = running_loss/(i+1)\n",
        "        else:\n",
        "            print(f'epoch {epoch+1}, validation loss = {running_loss/(i+1)}, lowest validation loss = False, do not save model')\n",
        "        valid_loss.append(running_loss/(i+1))\n",
        "        \n",
        "        counter += 1\n",
        "\n",
        "        # Regularly save models between save_epoch epochs, for resuming training\n",
        "        if counter == save_epoch:\n",
        "            counter = 0\n",
        "            torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'bert_optimizer_state_dict': bert_optimizer.state_dict(),\n",
        "            'classifier_optimizer_state_dict': classifier_optimizer.state_dict(),\n",
        "            'training_loss': train_loss,\n",
        "            'validation_loss': valid_loss,\n",
        "            'min_valid_loss': min_valid_loss\n",
        "            }, f'{checkpoint_path}_{backup}.pt')\n",
        "            print(f'Model checkpoint has been saved to {checkpoint_path}_{backup}.pt')\n",
        "            if backup == 0:\n",
        "                backup = 1\n",
        "            else:\n",
        "                backup = 0\n",
        "        with open(f'{model_name}_train_loss.txt', 'w') as f:\n",
        "          for line in train_loss:\n",
        "              f.write(str(line))\n",
        "              f.write(' ')\n",
        "        with open(f'{model_name}_val_loss.txt', 'w') as f:\n",
        "          for line in valid_loss:\n",
        "              f.write(str(line))\n",
        "              f.write(' ')\n",
        "        print('Loss has been updated.')\n",
        "\n",
        "    return model, train_loss, valid_loss"
      ],
      "metadata": {
        "id": "Dd-3Js0QO83Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Hyperparameters"
      ],
      "metadata": {
        "id": "rA3-4R_8Tl-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 10\n",
        "bert_learning_rate = 2e-5\n",
        "classifier_learning_rate = 1e-3\n",
        "batch_size = 70\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_QA = nn.BCEWithLogitsLoss()\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "4vZZRoiGTp76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification Model Training"
      ],
      "metadata": {
        "id": "CgiZBfF1yX1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Binary Dataset for BertPlain and BertAll"
      ],
      "metadata": {
        "id": "RM-5q53ABqWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_train_set = SST2_Dataset('data/binary_train.csv')\n",
        "binary_val_set = SST2_Dataset('data/binary_val.csv')\n",
        "# binary_test_set = SST2_Dataset('data/binary_test.csv')"
      ],
      "metadata": {
        "id": "7GOhOk43BeJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "cPFTBh5NSRL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlain = BertClassifier(num_classes=2, mode='plain')"
      ],
      "metadata": {
        "id": "IUSRRthPPEpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlain, binaryBertPlain_train_loss, binaryBertPlain_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer,\n",
        "    model=binaryBertPlain, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertPlain', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=binary_train_set, \n",
        "    val_set=binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertPlain_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=False\n",
        ")"
      ],
      "metadata": {
        "id": "MoEhSVbnPxoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "MgX7vbVKQPBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlainPart = BertClassifier(num_classes=2, mode='plain')"
      ],
      "metadata": {
        "id": "Z8jMWxiRQMfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlainPart, binaryBertPlainPart_train_loss, binaryBertPlainPart_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer,\n",
        "    model=binaryBertPlainPart, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertPlainPart', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=binary_train_set, \n",
        "    val_set=binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertPlainPart_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=True\n",
        ")"
      ],
      "metadata": {
        "id": "uFSdQ2ecQMf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "BBnHA9aIzMB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALL = BertClassifier(num_classes=2, mode='all')"
      ],
      "metadata": {
        "id": "KQUfVRMszMB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALL, binaryBertALL_train_loss, binaryBertALL_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertALL, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertALL', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=binary_train_set, \n",
        "    val_set=binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertALL_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=False\n",
        ")"
      ],
      "metadata": {
        "id": "yX-X8-RfzMB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "CGHduGniQiBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALLPart = BertClassifier(num_classes=2, mode='all')"
      ],
      "metadata": {
        "id": "To7eqxUsQqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALLPart, binaryBertALLPart_train_loss, binaryBertALLPart_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertALLPart, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertALLPart', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=binary_train_set, \n",
        "    val_set=binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertALLPart_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=True\n",
        ")"
      ],
      "metadata": {
        "id": "P36Z61yMQqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Binary Dataset for BertQA with True/False Answer"
      ],
      "metadata": {
        "id": "d6xgI5ljBxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_binary_train_set = SST2_Dataset('data/binary_train_QA_TF.csv', True)\n",
        "TF_binary_val_set = SST2_Dataset('data/binary_val_QA_TF.csv', True)\n",
        "# TF_binary_test_set = SST2_Dataset('data/binary_test_QA_TF.csv', True)"
      ],
      "metadata": {
        "id": "GIZ4-_m6IkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "pcbxzQEqzM8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATF = BertClassifier(num_classes=1, mode='qa')"
      ],
      "metadata": {
        "id": "bw2VATI1zM8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATF, binaryBertQATF_train_loss, binaryBertQATF_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertQATF, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertQATF', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=TF_binary_train_set, \n",
        "    val_set=TF_binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion_QA, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertQATF_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=False,\n",
        "    is_QA=True\n",
        ")"
      ],
      "metadata": {
        "id": "i82AwBiNzM8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "2eLh5OrPR0Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATFPart = BertClassifier(num_classes=1, mode='qa')"
      ],
      "metadata": {
        "id": "vzQ-AXVKR0Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATFPart, binaryBertQATFPart_train_loss, binaryBertQATFPart_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertQATFPart, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertQATFPart', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=TF_binary_train_set, \n",
        "    val_set=TF_binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion_QA, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertQATFPart_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=True,\n",
        "    is_QA=True\n",
        ")"
      ],
      "metadata": {
        "id": "2O47xRP8R0Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Binary Dataset for BertQA with Positive/Negative Answer"
      ],
      "metadata": {
        "id": "L_y0IY3uO3nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PN_binary_train_set = SST2_Dataset('data/binary_train_QA_PN.csv', True)\n",
        "PN_binary_val_set = SST2_Dataset('data/binary_val_QA_PN.csv', True)\n",
        "# PN_binary_test_set = SST2_Dataset('data/binary_test_QA_PN.csv', True)"
      ],
      "metadata": {
        "id": "JuxfPKlPO3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "JVhcK4eCO3ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPN = BertClassifier(num_classes=1, mode='qa')"
      ],
      "metadata": {
        "id": "dWWOGgX5O3ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPN, binaryBertQAPN_train_loss, binaryBertQAPN_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertQAPN, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertQAPN', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=PN_binary_train_set, \n",
        "    val_set=PN_binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion_QA, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertQAPN_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=False,\n",
        "    is_QA=True\n",
        ")"
      ],
      "metadata": {
        "id": "yPgTnG9vO3nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "RPyYXKAiR-R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPNPart = BertClassifier(num_classes=1, mode='qa')"
      ],
      "metadata": {
        "id": "KWNwna33R-R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPNPart, binaryBertQAPNPart_train_loss, binaryBertQAPNPart_valid_loss = train_bert_classifier(\n",
        "    tokenizer=tokenizer, \n",
        "    model=binaryBertQAPNPart, \n",
        "    model_name='/content/gdrive/MyDrive/binaryBertQAPNPart', \n",
        "    bert_learning_rate=bert_learning_rate,\n",
        "    classifier_learning_rate=classifier_learning_rate,\n",
        "    train_set=PN_binary_train_set, \n",
        "    val_set=PN_binary_val_set, \n",
        "    batch_size=batch_size, \n",
        "    num_epochs=num_epochs, \n",
        "    device=device, \n",
        "    criterion=criterion_QA, \n",
        "    checkpoint_path='/content/gdrive/MyDrive/binaryBertQAPNPart_checkpoint',\n",
        "    resume_training=False, # Set this to True if you want to restore training\n",
        "    save_epoch=10,\n",
        "    last_backup=0,\n",
        "    train_part=True,\n",
        "    is_QA=True\n",
        ")"
      ],
      "metadata": {
        "id": "MSl-_qopR-R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "For Lecturers and TAs, you don't have to run this part.\n",
        "\n",
        "      1. This part is used to get the test results, as well as the loss plot.\n",
        "      2. Each Model is deleted from memory after its evaluation. Otherwise the memory will not be enough."
      ],
      "metadata": {
        "id": "lg-c0IO7Vp8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_prediction(model, test_set, batch_size, tokenizer, device, is_QA=False, QA_keywords=None):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    testloader = DataLoader(test_set, batch_size)\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    \n",
        "    if is_QA:\n",
        "        \n",
        "        for i, test_data in enumerate(testloader):\n",
        "\n",
        "            inputs, labels = test_data\n",
        "            temp = []\n",
        "\n",
        "            for key_word_ind in range(len(QA_keywords)):\n",
        "\n",
        "                x_args = tokenizer([[inputs[j], QA_keywords[key_word_ind]] for j in range(len(labels))],return_tensors='pt',padding=True).to(device)\n",
        "                outputs=model(x_args)\n",
        "                temp.append(outputs)\n",
        "\n",
        "            y_pred.extend(torch.argmax(torch.concat(temp,dim=1),dim=1))\n",
        "            y_true.extend(list(labels))\n",
        "\n",
        "    else:\n",
        "\n",
        "        for i, test_data in enumerate(testloader):\n",
        "\n",
        "            inputs, labels = test_data\n",
        "            x_args = tokenizer(list(inputs),return_tensors='pt',padding=True).to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = torch.argmax(model(x_args),dim=1)\n",
        "            y_pred.extend(list(outputs))\n",
        "            y_true.extend(list(labels))\n",
        "\n",
        "    return torch.tensor(y_pred), torch.tensor(y_true)"
      ],
      "metadata": {
        "id": "s1bvagar8ycQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_pred, y_true):\n",
        "    accuracy = torch.sum(y_pred == y_true)/((torch.sum(y_pred == y_true))+torch.sum(y_pred != y_true))\n",
        "    precision = torch.sum(y_pred[y_true == 1] == 1)/torch.sum(y_true == 1)\n",
        "    recall = torch.sum(y_pred[y_true == 1] == 1)/(torch.sum(y_pred[y_true == 1] == 1) + torch.sum(y_pred[y_true == 0] == 1))\n",
        "    F_1 = 2*precision*recall/(precision+recall)\n",
        "    return precision, recall, accuracy, F_1"
      ],
      "metadata": {
        "id": "n2Zfj0JVigSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_result(model_name, precision, recall, accuracy, F_1):\n",
        "    print(f'Model = {model_name}, Precision = {precision}, Recall = {recall}, Accuracy = {accuracy}, F1 Score = {F_1}')"
      ],
      "metadata": {
        "id": "oaxRL0C_qdn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 70\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "Mev-g6qAGZei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary"
      ],
      "metadata": {
        "id": "e_7Eyja18pH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_test_set = SST2_Dataset('data/binary_test.csv')"
      ],
      "metadata": {
        "id": "D8gAvoQkF-yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['binaryBertPlain','binaryBertALL','binaryBertQATF','binaryBertQAPN','binaryBertPlainPart', 'binaryBertALLPart', 'binaryBertQATFPart', 'binaryBertQAPNPart']"
      ],
      "metadata": {
        "id": "wj_DxQjMFaVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "TG8PdU-iFEUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(train_losses, valid_losses, model_names):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    for i in range(len(model_names)):\n",
        "        plt.plot(train_losses[i], linestyle='-', c=f'C{i}', label=f'{model_names[i][6:]}')\n",
        "        plt.plot(valid_losses[i], linestyle='--', c=f'C{i}')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('# of Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eLejtAahATBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "for model_name in model_names:\n",
        "    with open(f'models/{model_name}_train_loss.txt') as f:\n",
        "      train_losses.append(list(map(float,f.readline().split()))[:10])\n",
        "    with open(f'models/{model_name}_val_loss.txt') as f:\n",
        "      valid_losses.append(list(map(float,f.readline().split()))[:10])"
      ],
      "metadata": {
        "id": "JMmjUGONBugU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(train_losses, valid_losses, model_names)"
      ],
      "metadata": {
        "id": "aL5mr8OxChAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "rLzVywD_F7Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlain = BertClassifier(num_classes=2, mode='plain').to(device)\n",
        "binaryBertPlain.load_state_dict(torch.load('models/binaryBertPlain.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertPlain, binary_test_set, batch_size, tokenizer, device)\n",
        "del binaryBertPlain"
      ],
      "metadata": {
        "id": "quj9pChNF7Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertPlain', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "FWHVtsswGN1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "ok88XwwUF7Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlainPart = BertClassifier(num_classes=2, mode='plain').to(device)\n",
        "binaryBertPlainPart.load_state_dict(torch.load('models/binaryBertPlainPart.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertPlainPart, binary_test_set, batch_size, tokenizer, device)\n",
        "del binaryBertPlainPart"
      ],
      "metadata": {
        "id": "2ZNgY9MWF7Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertPlainPart', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "uPAo_jjdF7Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "HkSojvR0F7Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALL = BertClassifier(num_classes=2, mode='all').to(device)\n",
        "binaryBertALL.load_state_dict(torch.load('models/binaryBertALL.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertALL, binary_test_set, batch_size, tokenizer, device)\n",
        "del binaryBertALL"
      ],
      "metadata": {
        "id": "n-N9s1bEF7Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertALL', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "Iv_mMxSpF7Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "uF5sObHkF7Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALLPart = BertClassifier(num_classes=2, mode='all').to(device)\n",
        "binaryBertALLPart.load_state_dict(torch.load('models/binaryBertALLPart.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertALLPart, binary_test_set, batch_size, tokenizer, device)\n",
        "del binaryBertALLPart"
      ],
      "metadata": {
        "id": "fmNLV7fcF7Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertALLPart', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "8GqKEvZ6F7Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "ACpKg_v0F7Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATF = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQATF.load_state_dict(torch.load('models/binaryBertQATF.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertQATF, binary_test_set, batch_size, tokenizer, device, True, ['False', 'True'])\n",
        "del binaryBertQATF"
      ],
      "metadata": {
        "id": "g8CgIH7iF7Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertQATF', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "W1CFfBUFF7Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "bqTY3SiqF7Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATFPart = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQATFPart.load_state_dict(torch.load('models/binaryBertQATFPart.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertQATFPart, binary_test_set, batch_size, tokenizer, device, True, ['False', 'True'])\n",
        "del binaryBertQATFPart"
      ],
      "metadata": {
        "id": "JcSwwsuIF7Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertQATFPart', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "4-5X4zcHF7Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "oDGtdqyZF7A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPN = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQAPN.load_state_dict(torch.load('models/binaryBertQAPN.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertQAPN, binary_test_set, batch_size, tokenizer, device, True, ['Negative','Positive'])\n",
        "del binaryBertQAPN"
      ],
      "metadata": {
        "id": "d_Tmi_ucF7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertQAPN', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "uO7zohqjF7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "Jwm2Cwg0F7A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPNPart = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQAPNPart.load_state_dict(torch.load('models/binaryBertQAPNPart.pt',map_location=device))\n",
        "y_pred, y_true = retrieve_prediction(binaryBertQAPNPart, binary_test_set, batch_size, tokenizer, device, True, ['Negative','Positive'])\n",
        "del binaryBertQAPNPart"
      ],
      "metadata": {
        "id": "K_krLsJaF7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, accuracy, F_1 = get_metrics(y_pred, y_true)\n",
        "report_result('binaryBertQAPNPart', precision, recall, accuracy, F_1)"
      ],
      "metadata": {
        "id": "T7YqThJQF7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify Successful/Fail Cases for Each Algorithm\n",
        "\n",
        "For Lecturers and TAs, you don't have to run this part.\n",
        "\n",
        "      How the samples of qualitative analysis are retrieved is in this part."
      ],
      "metadata": {
        "id": "Y4AM3W1jLc2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_test_set = SST2_Dataset('data/binary_test.csv')\n",
        "testloader = DataLoader(binary_test_set, 1)"
      ],
      "metadata": {
        "id": "23NNP76NLlF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "binaryBertPlain = BertClassifier(num_classes=2, mode='plain').to(device)\n",
        "binaryBertPlain.load_state_dict(torch.load('models/binaryBertPlain.pt',map_location=device))\n",
        "binaryBertPlain.eval()\n",
        "binaryBertALL = BertClassifier(num_classes=2, mode='all').to(device)\n",
        "binaryBertALL.load_state_dict(torch.load('models/binaryBertALL.pt',map_location=device))\n",
        "binaryBertALL.eval()\n",
        "binaryBertQATF = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQATF.load_state_dict(torch.load('models/binaryBertQATF.pt',map_location=device))\n",
        "binaryBertQATF.eval()\n",
        "binaryBertQAPN = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQAPN.load_state_dict(torch.load('models/binaryBertQAPN.pt',map_location=device))\n",
        "binaryBertQAPN.eval()"
      ],
      "metadata": {
        "id": "AE1OqMNiM3_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame({'Sentence':[],'Label':[],'BERT-Plain-C':[],'BERT-ALL-C':[],'BERT-QA-TF-C':[],'BERT-QA-PN-C':[]})\n",
        "for i, testdata in enumerate(testloader):\n",
        "    x, y = testdata\n",
        "    x = x[0]\n",
        "    binaryBertPlainresult = binaryBertPlain.predict(x, tokenizer, device)\n",
        "    binaryBertALLresult = binaryBertALL.predict(x, tokenizer, device)\n",
        "    binaryBertQATFresult = binaryBertQATF.predict(x, tokenizer, device, ['False', 'True'])\n",
        "    binaryBertQAPNresult = binaryBertQAPN.predict(x, tokenizer, device, ['Negative', 'Positive'])\n",
        "    df = pd.DataFrame({'Sentence':[x],'Label':[int(y)],'BERT-Plain-C':[int(binaryBertPlainresult)],'BERT-ALL-C':[int(binaryBertALLresult)],'BERT-QA-TF-C':[int(binaryBertQATFresult)],'BERT-QA-PN-C':[int(binaryBertQAPNresult)]})\n",
        "    pred = pd.concat([pred,df])\n",
        "    # print(f'Sentence={x}, Correct Label={y}, PlainLabel={binaryBertPlainresult}, ALLLabel={binaryBertALLresult}, QATFLabel={binaryBertQATFresult}, QAPNLabel={binaryBertQAPNresult}')"
      ],
      "metadata": {
        "id": "EV0areLwMCoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.to_csv('pred.csv',index=False)"
      ],
      "metadata": {
        "id": "Xp065E5BYSPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertPlain\n",
        "del binaryBertALL\n",
        "del binaryBertQATF\n",
        "del binaryBertQAPN\n",
        "del pred"
      ],
      "metadata": {
        "id": "n10u4DEsY4Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing\n",
        "\n",
        "Lecturers and TAs, in the following cells you can test the model performance by writing a sentence.\n",
        "\n",
        "      1. The implementation is not batched, so only one sentence can be put into them. An example of testing each of the model is given in the cells below. \n",
        "      2. In this training set, 0 represents positive sentiment while 1 represents negative sentiment. It's important to put the correct according candidate answers for BERT-QA.\n",
        "      3. It is crucial to release the memory if you want to test many models.\n"
      ],
      "metadata": {
        "id": "b4wYvQkiluMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "dySDylE8mkjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_sentiment(sentence, sentiment):\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(f'Sentence \\\"{sentence}\\\" shows a positive sentiment.')\n",
        "    else:\n",
        "        print(f'Sentence \\\"{sentence}\\\" shows a negative sentiment.')"
      ],
      "metadata": {
        "id": "fDpBGCYIn9gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "Uaz9JLfTlz2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlain = BertClassifier(num_classes=2, mode='plain').to(device)\n",
        "binaryBertPlain.load_state_dict(torch.load('models/binaryBertPlain.pt',map_location=device))\n",
        "binaryBertPlain.eval()"
      ],
      "metadata": {
        "id": "Rntnda--lz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertPlain.predict(sentence, tokenizer, device)"
      ],
      "metadata": {
        "id": "km_uHa_wmqcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "IwENxTDgoNA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertPlain"
      ],
      "metadata": {
        "id": "CF0k5UQxpE1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertPlain (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "CdtXjsqjlz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertPlainPart = BertClassifier(num_classes=2, mode='plain').to(device)\n",
        "binaryBertPlainPart.load_state_dict(torch.load('models/binaryBertPlainPart.pt',map_location=device))\n",
        "binaryBertPlainPart.eval()"
      ],
      "metadata": {
        "id": "063Xsrkxlz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertPlainPart.predict(sentence, tokenizer, device)"
      ],
      "metadata": {
        "id": "AKKga9zIpdPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "IUaufEFvpdVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertPlainPart"
      ],
      "metadata": {
        "id": "xHmjmzCEpe03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "SGylnZ9Glz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALL = BertClassifier(num_classes=2, mode='all').to(device)\n",
        "binaryBertALL.load_state_dict(torch.load('models/binaryBertALL.pt',map_location=device))\n",
        "binaryBertALL.eval()"
      ],
      "metadata": {
        "id": "P3EOuBJglz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertALL.predict(sentence, tokenizer, device)"
      ],
      "metadata": {
        "id": "J-ZIUoWhm7OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "QbxawINzpOwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertALL"
      ],
      "metadata": {
        "id": "SKZb5boFpVsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertALL (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "7Gn7KAgvlz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertALLPart = BertClassifier(num_classes=2, mode='all').to(device)\n",
        "binaryBertALLPart.load_state_dict(torch.load('models/binaryBertALLPart.pt',map_location=device))\n",
        "binaryBertALLPart.eval()"
      ],
      "metadata": {
        "id": "tylEAiMHlz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertALLPart.predict(sentence, tokenizer, device)"
      ],
      "metadata": {
        "id": "VcZlrWcYpl_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "N0yvXOwPpmIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertALLPart"
      ],
      "metadata": {
        "id": "uAEOSKCrpmxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "hGJqL4kilz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATF = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQATF.load_state_dict(torch.load('models/binaryBertQATF.pt',map_location=device))\n",
        "binaryBertQATF.eval()"
      ],
      "metadata": {
        "id": "vU7g1meClz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertQATF.predict(sentence, tokenizer, device, ['False', 'True'])"
      ],
      "metadata": {
        "id": "XXE6HWHbsSwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "qfSuJD2jsbx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertQATF"
      ],
      "metadata": {
        "id": "Dh2jXRCHtQL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with TF (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "plI65VM-lz2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQATFPart = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQATFPart.load_state_dict(torch.load('models/binaryBertQATFPart.pt',map_location=device))\n",
        "binaryBertQATFPart.eval()"
      ],
      "metadata": {
        "id": "ye17lWUklz2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertQATFPart.predict(sentence, tokenizer, device, ['False', 'True'])"
      ],
      "metadata": {
        "id": "o-GzFVx_tNyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "_BZFGXeptOxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertQATFPart"
      ],
      "metadata": {
        "id": "nCedorGmtR1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Complete fine-tuning)"
      ],
      "metadata": {
        "id": "CGMIVYLNlz2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPN = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQAPN.load_state_dict(torch.load('models/binaryBertQAPN.pt',map_location=device))\n",
        "binaryBertQAPN.eval()"
      ],
      "metadata": {
        "id": "8HYqfFkelz2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertQAPN.predict(sentence, tokenizer, device, ['Negative', 'Positive'])"
      ],
      "metadata": {
        "id": "dqXi5ABFt9rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "cUuA5nDBuAbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertQAPN"
      ],
      "metadata": {
        "id": "ZDjfXDnvuBPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BertQA with PN (Partial fine-tuning)"
      ],
      "metadata": {
        "id": "fReaS9ZWlz2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryBertQAPNPart = BertClassifier(num_classes=1, mode='qa').to(device)\n",
        "binaryBertQAPNPart.load_state_dict(torch.load('models/binaryBertQAPNPart.pt',map_location=device))\n",
        "binaryBertQAPNPart.eval()"
      ],
      "metadata": {
        "id": "74qKMUe3lz2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP is interesting!\"\n",
        "sentiment = binaryBertQAPNPart.predict(sentence, tokenizer, device, ['Negative', 'Positive'])"
      ],
      "metadata": {
        "id": "i8I_o_9BuGTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_sentiment(sentence, sentiment)"
      ],
      "metadata": {
        "id": "AwN7DjG0uGnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del binaryBertQAPNPart"
      ],
      "metadata": {
        "id": "7tFJPS8iuGv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}